{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textdistance\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "import parselmouth\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "file_name = \"all_spanish_letters_recordings/aphasia_letters.txt\"\n",
    "with open(file_name) as f:\n",
    "    all_recordings = f.readlines()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"consonant_types_with_sil.pickle\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "n_formants = 5\n",
    "\n",
    "def extract_formants_and_intensity_from_sound(snd):\n",
    "    formants = snd.to_formant_burg()\n",
    "    intensity = snd.to_intensity()\n",
    "    formant_list = [list() for _ in range(n_formants)]\n",
    "    intensity_list = list()\n",
    "    for t in formants.t_grid():\n",
    "        for f_n in range(n_formants):\n",
    "            formant_list[f_n].append(formants.get_value_at_time(f_n + 1,t))\n",
    "        intensity_list.append(intensity.get_value(t))\n",
    "\n",
    "    return *formant_list, intensity_list, formants.t_grid()\n",
    "\n",
    "remap = {\n",
    "    'nasal': 'n',\n",
    "    'sil': '',\n",
    "    'e': 'e',\n",
    "    'o': 'o',\n",
    "    'vibrant': 'R',\n",
    "    'u': 'u',\n",
    "    'plosive': 'p',\n",
    "    'a': 'a',\n",
    "    'voiceless': 'r',\n",
    "    'i': 'i',\n",
    "    'approximant': 'j',\n",
    "    'voiced': '',\n",
    "    'fricative': 'f'\n",
    "}\n",
    "def regroup(string):\n",
    "    current_string = string[0] if len(string) > 0 else \"\"\n",
    "    grouped_string = current_string\n",
    "    for letter in string:\n",
    "        if letter != current_string:\n",
    "            grouped_string += letter\n",
    "            current_string = letter\n",
    "    return grouped_string\n",
    "\n",
    "def translate(counter_array, threshold=8):\n",
    "    return ''.join([remap.get(phoneme, '') for phoneme, count in counter_array if count > threshold])\n",
    "\n",
    "def compress(array):\n",
    "    compressed_array = list()\n",
    "    counter = 0\n",
    "    current_element = array[0]\n",
    "    for element in array:\n",
    "        counter += 1\n",
    "        if element != current_element:\n",
    "            compressed_array.append((current_element, counter))\n",
    "            current_element = element\n",
    "            counter = 0\n",
    "    return compressed_array\n",
    "\n",
    "def recognize(record_path):\n",
    "\n",
    "    snd = parselmouth.Sound(record_path)\n",
    "    formants_plus_intensity = list()\n",
    "    for *values, t in zip(*extract_formants_and_intensity_from_sound(snd)):\n",
    "        formants_plus_intensity.append(values)\n",
    "\n",
    "    formant_names = [f\"f_{i+1}\" for i in range(5)]\n",
    "    column_names =  formant_names + [\"i\"]\n",
    "    data_frame = pd.DataFrame(formants_plus_intensity, columns=column_names)\n",
    "    data_frame[formant_names] = data_frame[formant_names].fillna(data_frame[column_names].mean())\n",
    "    data_frame[[\"i\"]] = data_frame[[\"i\"]].fillna(value=-300)\n",
    "    # data_frame[column_names] = data_frame[column_names].fillna(data_frame[column_names].mean())\n",
    "    # data_frame[[\"i\"]] = data_frame[[\"i\"]].fillna(value=-300)\n",
    "    return regroup(translate(compress(model.predict(data_frame))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found all_spanish_letters_recordings/aphasia_wav/aphasia/24410.wav\n",
      "a, a\n",
      "\n",
      "a, a\n",
      "\n",
      "a, a\n",
      "\n",
      "a, af\n",
      "\n",
      "a, a\n",
      "\n",
      "a, fa\n",
      "\n",
      "a, a\n",
      "\n",
      "a, a\n",
      "\n",
      "a, \n",
      "\n",
      "a, a\n",
      "\n",
      "a, a\n",
      "\n",
      "a, a\n",
      "\n",
      "be, fne\n",
      "\n",
      "be, e\n",
      "\n",
      "be, e\n",
      "\n",
      "be, eo\n",
      "\n",
      "be, no\n",
      "\n",
      "be, e\n",
      "\n",
      "be, e\n",
      "\n",
      "be, eo\n",
      "\n",
      "be, je\n",
      "\n",
      "be, a\n",
      "\n",
      "be, e\n",
      "\n",
      "ce, fe\n",
      "\n",
      "ce, e\n",
      "\n",
      "ce, e\n",
      "\n",
      "ce, e\n",
      "\n",
      "ce, o\n",
      "\n",
      "ce, e\n",
      "\n",
      "ce, e\n",
      "\n",
      "ce, en\n",
      "\n",
      "ce, f\n",
      "\n",
      "ce, a\n",
      "\n",
      "ce, fe\n",
      "\n",
      "de, fjf\n",
      "\n",
      "de, e\n",
      "\n",
      "de, e\n",
      "\n",
      "de, e\n",
      "\n",
      "de, oa\n",
      "\n",
      "de, je\n",
      "\n",
      "de, \n",
      "\n",
      "de, eo\n",
      "\n",
      "de, je\n",
      "\n",
      "de, e\n",
      "\n",
      "de, a\n",
      "\n",
      "de, je\n",
      "\n",
      "e, fef\n",
      "\n",
      "e, \n",
      "\n",
      "e, e\n",
      "\n",
      "e, oa\n",
      "\n",
      "e, e\n",
      "\n",
      "e, e\n",
      "\n",
      "e, jo\n",
      "\n",
      "e, \n",
      "\n",
      "e, e\n",
      "\n",
      "e, ae\n",
      "\n",
      "e, j\n",
      "\n",
      "efe, ef\n",
      "\n",
      "efe, e\n",
      "\n",
      "efe, \n",
      "\n",
      "efe, ofo\n",
      "\n",
      "efe, e\n",
      "\n",
      "efe, e\n",
      "\n",
      "efe, eje\n",
      "\n",
      "efe, j\n",
      "\n",
      "efe, fa\n",
      "\n",
      "efe, je\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, \n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, a\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, je\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, a\n",
      "\n",
      "ge, ej\n",
      "\n",
      "hache, af\n",
      "\n",
      "hache, e\n",
      "\n",
      "hache, a\n",
      "\n",
      "hache, afo\n",
      "\n",
      "hache, af\n",
      "\n",
      "hache, a\n",
      "\n",
      "hache, afen\n",
      "\n",
      "hache, \n",
      "\n",
      "hache, a\n",
      "\n",
      "hache, aej\n",
      "\n",
      "i, ej\n",
      "\n",
      "i, e\n",
      "\n",
      "i, e\n",
      "\n",
      "i, o\n",
      "\n",
      "i, e\n",
      "\n",
      "i, e\n",
      "\n",
      "i, jn\n",
      "\n",
      "i, e\n",
      "\n",
      "i, a\n",
      "\n",
      "i, jie\n",
      "\n",
      "jota, oa\n",
      "\n",
      "jota, oa\n",
      "\n",
      "jota, oa\n",
      "\n",
      "jota, aoa\n",
      "\n",
      "jota, o\n",
      "\n",
      "jota, o\n",
      "\n",
      "jota, oan\n",
      "\n",
      "jota, o\n",
      "\n",
      "jota, a\n",
      "\n",
      "jota, oe\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, an\n",
      "\n",
      "ka, eo\n",
      "\n",
      "ka, a\n",
      "\n",
      "ka, a\n",
      "\n",
      "ele, ejn\n",
      "\n",
      "ele, je\n",
      "\n",
      "ele, ej\n",
      "\n",
      "ele, o\n",
      "\n",
      "ele, ej\n",
      "\n",
      "ele, ej\n",
      "\n",
      "ele, jn\n",
      "\n",
      "ele, ej\n",
      "\n",
      "ele, aoa\n",
      "\n",
      "ele, j\n",
      "\n",
      "eme, j\n",
      "\n",
      "eme, j\n",
      "\n",
      "eme, ej\n",
      "\n",
      "eme, o\n",
      "\n",
      "eme, e\n",
      "\n",
      "eme, j\n",
      "\n",
      "eme, ejn\n",
      "\n",
      "eme, ej\n",
      "\n",
      "eme, fa\n",
      "\n",
      "eme, jn\n",
      "\n",
      "ene, j\n",
      "\n",
      "ene, \n",
      "\n",
      "ene, e\n",
      "\n",
      "ene, o\n",
      "\n",
      "ene, e\n",
      "\n",
      "ene, j\n",
      "\n",
      "ene, en\n",
      "\n",
      "ene, j\n",
      "\n",
      "ene, aoa\n",
      "\n",
      "ene, n\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, o\n",
      "\n",
      "o, a\n",
      "\n",
      "o, o\n",
      "\n",
      "pe, nf\n",
      "\n",
      "pe, e\n",
      "\n",
      "pe, e\n",
      "\n",
      "pe, oa\n",
      "\n",
      "pe, e\n",
      "\n",
      "pe, e\n",
      "\n",
      "pe, en\n",
      "\n",
      "pe, ej\n",
      "\n",
      "pe, aea\n",
      "\n",
      "pe, e\n",
      "\n",
      "qu, n\n",
      "\n",
      "qu, uo\n",
      "\n",
      "qu, o\n",
      "\n",
      "qu, o\n",
      "\n",
      "qu, o\n",
      "\n",
      "qu, n\n",
      "\n",
      "qu, o\n",
      "\n",
      "qu, un\n",
      "\n",
      "qu, a\n",
      "\n",
      "qu, o\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, eoa\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, e\n",
      "\n",
      "ere, a\n",
      "\n",
      "ere, ej\n",
      "\n",
      "ese, j\n",
      "\n",
      "ese, e\n",
      "\n",
      "ese, e\n",
      "\n",
      "ese, ofo\n",
      "\n",
      "ese, e\n",
      "\n",
      "ese, \n",
      "\n",
      "ese, ja\n",
      "\n",
      "ese, ej\n",
      "\n",
      "ese, a\n",
      "\n",
      "ese, jf\n",
      "\n",
      "te, e\n",
      "\n",
      "te, e\n",
      "\n",
      "te, eo\n",
      "\n",
      "te, a\n",
      "\n",
      "te, e\n",
      "\n",
      "te, j\n",
      "\n",
      "te, on\n",
      "\n",
      "te, e\n",
      "\n",
      "te, a\n",
      "\n",
      "te, e\n",
      "\n",
      "u, n\n",
      "\n",
      "u, o\n",
      "\n",
      "u, o\n",
      "\n",
      "u, o\n",
      "\n",
      "u, o\n",
      "\n",
      "u, n\n",
      "\n",
      "u, o\n",
      "\n",
      "u, n\n",
      "\n",
      "u, o\n",
      "\n",
      "u, n\n",
      "\n",
      "ve, je\n",
      "\n",
      "ve, e\n",
      "\n",
      "ve, eo\n",
      "\n",
      "ve, nao\n",
      "\n",
      "ve, e\n",
      "\n",
      "ve, \n",
      "\n",
      "ve, jean\n",
      "\n",
      "ve, e\n",
      "\n",
      "ve, aoaoe\n",
      "\n",
      "File not found all_spanish_letters_recordings/aphasia_wav/aphasia/36640.wav\n",
      "equis, \n",
      "\n",
      "equis, ef\n",
      "\n",
      "equis, e\n",
      "\n",
      "equis, of\n",
      "\n",
      "equis, e\n",
      "\n",
      "equis, \n",
      "\n",
      "equis, eje\n",
      "\n",
      "equis, e\n",
      "\n",
      "equis, fafaofaf\n",
      "\n",
      "equis, ji\n",
      "\n",
      "ye, n\n",
      "\n",
      "ye, e\n",
      "\n",
      "ye, e\n",
      "\n",
      "ye, noa\n",
      "\n",
      "ye, e\n",
      "\n",
      "ye, j\n",
      "\n",
      "ye, nja\n",
      "\n",
      "ye, jej\n",
      "\n",
      "ye, an\n",
      "\n",
      "ye, jie\n",
      "\n",
      "zeta, e\n",
      "\n",
      "zeta, fe\n",
      "\n",
      "zeta, a\n",
      "\n",
      "zeta, oa\n",
      "\n",
      "zeta, fe\n",
      "\n",
      "zeta, e\n",
      "\n",
      "zeta, eaf\n",
      "\n",
      "zeta, ef\n",
      "\n",
      "zeta, a\n",
      "\n",
      "zeta, ea\n",
      "\n",
      "zeta, ea\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"all_spanish_letters_recordings/aphasia_wav\"\n",
    "output = list()\n",
    "for record in all_recordings:\n",
    "    try:\n",
    "        record_name, transcription = record.replace(\"mp4\", \"wav\").replace(\"\\n\", \"\").split(\",\")\n",
    "        record_path = os.path.join(base_folder, record_name)\n",
    "        recognizer = recognize(record_path,)\n",
    "        current_line = f\"{transcription}, {recognizer}\\n\"\n",
    "        output.append(current_line)\n",
    "        print(current_line)\n",
    "    except parselmouth.PraatError:\n",
    "        print(\"File not found\", record_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "output_folder_name = \"decision_trees_folder_results\"\n",
    "os.makedirs(output_folder_name, exist_ok=True)\n",
    "output_base_name = \"consonant_types.txt\"\n",
    "with open(os.path.join(output_folder_name, output_base_name), \"w+\") as output_file:\n",
    "    output_file.writelines(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5617673579801623"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    total_real_phones += len(transcription)\n",
    "    total_distance += len(transcription) + textdistance.levenshtein(transcription, ipa_transcription)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Todos los fonemas: 0.5617673579801623"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5888888888888889"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocales = \"aeiou\"\n",
    "\n",
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    if transcription in vocales:\n",
    "        total_real_phones += len(transcription)\n",
    "        total_distance += len(transcription) + textdistance.levenshtein(transcription, ipa_transcription)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solo vocales: 0.5888888888888889\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5517241379310345"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocales_extremas = \"aiu\"\n",
    "\n",
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    if transcription in vocales_extremas:\n",
    "        total_real_phones += len(transcription)\n",
    "        total_distance += len(transcription) + textdistance.levenshtein(transcription, ipa_transcription)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vocales extremas: 0.5517241379310345\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "'abasa'"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regroup(\"aaaabbaaaassa\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}