{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import textdistance\n",
    "from allosaurus.app import read_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['aphasia/24410.mp4,a\\n',\n 'aphasia/24418.mp4,a\\n',\n 'aphasia/24689.mp4,a\\n',\n 'aphasia/24740.mp4,a\\n',\n 'aphasia/25130.mp4,a\\n',\n 'aphasia/25144.mp4,a\\n',\n 'aphasia/25475.mp4,a\\n',\n 'aphasia/26352.mp4,a\\n',\n 'aphasia/26400.mp4,a\\n',\n 'aphasia/26597.mp4,a\\n',\n 'aphasia/26604.mp4,a\\n',\n 'aphasia/32053.mp4,a\\n',\n 'aphasia/36558.mp4,a\\n',\n 'aphasia/24416.mp4,be\\n',\n 'aphasia/24690.mp4,be\\n',\n 'aphasia/24741.mp4,be\\n',\n 'aphasia/25131.mp4,be\\n',\n 'aphasia/25145.mp4,be\\n',\n 'aphasia/25476.mp4,be\\n',\n 'aphasia/26353.mp4,be\\n',\n 'aphasia/26401.mp4,be\\n',\n 'aphasia/26598.mp4,be\\n',\n 'aphasia/32054.mp4,be\\n',\n 'aphasia/36559.mp4,be\\n',\n 'aphasia/24417.mp4,ce\\n',\n 'aphasia/24691.mp4,ce\\n',\n 'aphasia/24742.mp4,ce\\n',\n 'aphasia/25132.mp4,ce\\n',\n 'aphasia/25146.mp4,ce\\n',\n 'aphasia/25477.mp4,ce\\n',\n 'aphasia/26354.mp4,ce\\n',\n 'aphasia/26402.mp4,ce\\n',\n 'aphasia/26599.mp4,ce\\n',\n 'aphasia/32055.mp4,ce\\n',\n 'aphasia/36560.mp4,ce\\n',\n 'aphasia/24420.mp4,de\\n',\n 'aphasia/24692.mp4,de\\n',\n 'aphasia/24717.mp4,de\\n',\n 'aphasia/24743.mp4,de\\n',\n 'aphasia/25147.mp4,de\\n',\n 'aphasia/25478.mp4,de\\n',\n 'aphasia/26355.mp4,de\\n',\n 'aphasia/26403.mp4,de\\n',\n 'aphasia/26600.mp4,de\\n',\n 'aphasia/26603.mp4,de\\n',\n 'aphasia/32056.mp4,de\\n',\n 'aphasia/36561.mp4,de\\n',\n 'aphasia/24421.mp4,e\\n',\n 'aphasia/24693.mp4,e\\n',\n 'aphasia/24744.mp4,e\\n',\n 'aphasia/25148.mp4,e\\n',\n 'aphasia/25479.mp4,e\\n',\n 'aphasia/26356.mp4,e\\n',\n 'aphasia/26404.mp4,e\\n',\n 'aphasia/26601.mp4,e\\n',\n 'aphasia/26602.mp4,e\\n',\n 'aphasia/32057.mp4,e\\n',\n 'aphasia/36562.mp4,e\\n',\n 'aphasia/24422.mp4,efe\\n',\n 'aphasia/24694.mp4,efe\\n',\n 'aphasia/24745.mp4,efe\\n',\n 'aphasia/25149.mp4,efe\\n',\n 'aphasia/25480.mp4,efe\\n',\n 'aphasia/26357.mp4,efe\\n',\n 'aphasia/26405.mp4,efe\\n',\n 'aphasia/26605.mp4,efe\\n',\n 'aphasia/32058.mp4,efe\\n',\n 'aphasia/36563.mp4,efe\\n',\n 'aphasia/24423.mp4,ge\\n',\n 'aphasia/24695.mp4,ge\\n',\n 'aphasia/24746.mp4,ge\\n',\n 'aphasia/25150.mp4,ge\\n',\n 'aphasia/25481.mp4,ge\\n',\n 'aphasia/26358.mp4,ge\\n',\n 'aphasia/26406.mp4,ge\\n',\n 'aphasia/26606.mp4,ge\\n',\n 'aphasia/32059.mp4,ge\\n',\n 'aphasia/36564.mp4,ge\\n',\n 'aphasia/24424.mp4,hache\\n',\n 'aphasia/24696.mp4,hache\\n',\n 'aphasia/24747.mp4,hache\\n',\n 'aphasia/25151.mp4,hache\\n',\n 'aphasia/25482.mp4,hache\\n',\n 'aphasia/26359.mp4,hache\\n',\n 'aphasia/26407.mp4,hache\\n',\n 'aphasia/26607.mp4,hache\\n',\n 'aphasia/32060.mp4,hache\\n',\n 'aphasia/36565.mp4,hache\\n',\n 'aphasia/24425.mp4,i\\n',\n 'aphasia/24697.mp4,i\\n',\n 'aphasia/24748.mp4,i\\n',\n 'aphasia/25152.mp4,i\\n',\n 'aphasia/25483.mp4,i\\n',\n 'aphasia/26360.mp4,i\\n',\n 'aphasia/26408.mp4,i\\n',\n 'aphasia/26608.mp4,i\\n',\n 'aphasia/32061.mp4,i\\n',\n 'aphasia/36566.mp4,i\\n',\n 'aphasia/24426.mp4,jota\\n',\n 'aphasia/24698.mp4,jota\\n',\n 'aphasia/24749.mp4,jota\\n',\n 'aphasia/25153.mp4,jota\\n',\n 'aphasia/25484.mp4,jota\\n',\n 'aphasia/26361.mp4,jota\\n',\n 'aphasia/26409.mp4,jota\\n',\n 'aphasia/26609.mp4,jota\\n',\n 'aphasia/32062.mp4,jota\\n',\n 'aphasia/36567.mp4,jota\\n',\n 'aphasia/24427.mp4,ka\\n',\n 'aphasia/24699.mp4,ka\\n',\n 'aphasia/24750.mp4,ka\\n',\n 'aphasia/25154.mp4,ka\\n',\n 'aphasia/25485.mp4,ka\\n',\n 'aphasia/26362.mp4,ka\\n',\n 'aphasia/26410.mp4,ka\\n',\n 'aphasia/26610.mp4,ka\\n',\n 'aphasia/32063.mp4,ka\\n',\n 'aphasia/36568.mp4,ka\\n',\n 'aphasia/24428.mp4,ele\\n',\n 'aphasia/24700.mp4,ele\\n',\n 'aphasia/24751.mp4,ele\\n',\n 'aphasia/25155.mp4,ele\\n',\n 'aphasia/25486.mp4,ele\\n',\n 'aphasia/26363.mp4,ele\\n',\n 'aphasia/26411.mp4,ele\\n',\n 'aphasia/26611.mp4,ele\\n',\n 'aphasia/32064.mp4,ele\\n',\n 'aphasia/36630.mp4,ele\\n',\n 'aphasia/24429.mp4,eme\\n',\n 'aphasia/24701.mp4,eme\\n',\n 'aphasia/24752.mp4,eme\\n',\n 'aphasia/25156.mp4,eme\\n',\n 'aphasia/25487.mp4,eme\\n',\n 'aphasia/26364.mp4,eme\\n',\n 'aphasia/26412.mp4,eme\\n',\n 'aphasia/26612.mp4,eme\\n',\n 'aphasia/32065.mp4,eme\\n',\n 'aphasia/36631.mp4,eme\\n',\n 'aphasia/24430.mp4,ene\\n',\n 'aphasia/24702.mp4,ene\\n',\n 'aphasia/24753.mp4,ene\\n',\n 'aphasia/25157.mp4,ene\\n',\n 'aphasia/25488.mp4,ene\\n',\n 'aphasia/26365.mp4,ene\\n',\n 'aphasia/26413.mp4,ene\\n',\n 'aphasia/26613.mp4,ene\\n',\n 'aphasia/32066.mp4,ene\\n',\n 'aphasia/36632.mp4,ene\\n',\n 'aphasia/24431.mp4,o\\n',\n 'aphasia/24703.mp4,o\\n',\n 'aphasia/24754.mp4,o\\n',\n 'aphasia/25158.mp4,o\\n',\n 'aphasia/25489.mp4,o\\n',\n 'aphasia/26366.mp4,o\\n',\n 'aphasia/26414.mp4,o\\n',\n 'aphasia/26614.mp4,o\\n',\n 'aphasia/32067.mp4,o\\n',\n 'aphasia/36633.mp4,o\\n',\n 'aphasia/24432.mp4,pe\\n',\n 'aphasia/24704.mp4,pe\\n',\n 'aphasia/24755.mp4,pe\\n',\n 'aphasia/25159.mp4,pe\\n',\n 'aphasia/25490.mp4,pe\\n',\n 'aphasia/26367.mp4,pe\\n',\n 'aphasia/26415.mp4,pe\\n',\n 'aphasia/26615.mp4,pe\\n',\n 'aphasia/32068.mp4,pe\\n',\n 'aphasia/36634.mp4,pe\\n',\n 'aphasia/24433.mp4,qu\\n',\n 'aphasia/24705.mp4,qu\\n',\n 'aphasia/24756.mp4,qu\\n',\n 'aphasia/25160.mp4,qu\\n',\n 'aphasia/25491.mp4,qu\\n',\n 'aphasia/26368.mp4,qu\\n',\n 'aphasia/26416.mp4,qu\\n',\n 'aphasia/26616.mp4,qu\\n',\n 'aphasia/32069.mp4,qu\\n',\n 'aphasia/36635.mp4,qu\\n',\n 'aphasia/24434.mp4,ere\\n',\n 'aphasia/24706.mp4,ere\\n',\n 'aphasia/24757.mp4,ere\\n',\n 'aphasia/25161.mp4,ere\\n',\n 'aphasia/25492.mp4,ere\\n',\n 'aphasia/26369.mp4,ere\\n',\n 'aphasia/26417.mp4,ere\\n',\n 'aphasia/26617.mp4,ere\\n',\n 'aphasia/32070.mp4,ere\\n',\n 'aphasia/36636.mp4,ere\\n',\n 'aphasia/24435.mp4,ese\\n',\n 'aphasia/24707.mp4,ese\\n',\n 'aphasia/24758.mp4,ese\\n',\n 'aphasia/25162.mp4,ese\\n',\n 'aphasia/25493.mp4,ese\\n',\n 'aphasia/26370.mp4,ese\\n',\n 'aphasia/26418.mp4,ese\\n',\n 'aphasia/26618.mp4,ese\\n',\n 'aphasia/32071.mp4,ese\\n',\n 'aphasia/36637.mp4,ese\\n',\n 'aphasia/24436.mp4,te\\n',\n 'aphasia/24708.mp4,te\\n',\n 'aphasia/24759.mp4,te\\n',\n 'aphasia/25163.mp4,te\\n',\n 'aphasia/25494.mp4,te\\n',\n 'aphasia/26371.mp4,te\\n',\n 'aphasia/26419.mp4,te\\n',\n 'aphasia/26619.mp4,te\\n',\n 'aphasia/32072.mp4,te\\n',\n 'aphasia/36638.mp4,te\\n',\n 'aphasia/24437.mp4,u\\n',\n 'aphasia/24709.mp4,u\\n',\n 'aphasia/24760.mp4,u\\n',\n 'aphasia/25164.mp4,u\\n',\n 'aphasia/25495.mp4,u\\n',\n 'aphasia/26372.mp4,u\\n',\n 'aphasia/26420.mp4,u\\n',\n 'aphasia/26620.mp4,u\\n',\n 'aphasia/32073.mp4,u\\n',\n 'aphasia/36639.mp4,u\\n',\n 'aphasia/24438.mp4,ve\\n',\n 'aphasia/24710.mp4,ve\\n',\n 'aphasia/24761.mp4,ve\\n',\n 'aphasia/25165.mp4,ve\\n',\n 'aphasia/25496.mp4,ve\\n',\n 'aphasia/26373.mp4,ve\\n',\n 'aphasia/26421.mp4,ve\\n',\n 'aphasia/26621.mp4,ve\\n',\n 'aphasia/32074.mp4,ve\\n',\n 'aphasia/36640.mp4,ve\\n',\n 'aphasia/24439.mp4,equis\\n',\n 'aphasia/24711.mp4,equis\\n',\n 'aphasia/24762.mp4,equis\\n',\n 'aphasia/25166.mp4,equis\\n',\n 'aphasia/25497.mp4,equis\\n',\n 'aphasia/26374.mp4,equis\\n',\n 'aphasia/26422.mp4,equis\\n',\n 'aphasia/26622.mp4,equis\\n',\n 'aphasia/32075.mp4,equis\\n',\n 'aphasia/36641.mp4,equis\\n',\n 'aphasia/24440.mp4,ye\\n',\n 'aphasia/24712.mp4,ye\\n',\n 'aphasia/24763.mp4,ye\\n',\n 'aphasia/25167.mp4,ye\\n',\n 'aphasia/25498.mp4,ye\\n',\n 'aphasia/26375.mp4,ye\\n',\n 'aphasia/26423.mp4,ye\\n',\n 'aphasia/26623.mp4,ye\\n',\n 'aphasia/32076.mp4,ye\\n',\n 'aphasia/36642.mp4,ye\\n',\n 'aphasia/24441.mp4,zeta\\n',\n 'aphasia/24713.mp4,zeta\\n',\n 'aphasia/24764.mp4,zeta\\n',\n 'aphasia/25168.mp4,zeta\\n',\n 'aphasia/25499.mp4,zeta\\n',\n 'aphasia/26376.mp4,zeta\\n',\n 'aphasia/26424.mp4,zeta\\n',\n 'aphasia/26624.mp4,zeta\\n',\n 'aphasia/32077.mp4,zeta\\n',\n 'aphasia/36643.mp4,zeta\\n',\n 'aphasia/36644.mp4,zeta\\n']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"all_spanish_letters_recordings/aphasia_letters.txt\"\n",
    "with open(file_name) as f:\n",
    "    all_recordings = f.readlines()\n",
    "all_recordings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = read_recognizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found all_spanish_letters_recordings/aphasia_wav/aphasia/24410.wav\n",
      "a, a ɾ ɛ t\n",
      "\n",
      "a, x ɔ\n",
      "\n",
      "a, æ\n",
      "\n",
      "a, e\n",
      "\n",
      "a, k ɛ a\n",
      "\n",
      "a, t̪ e s a ɾ s̪ i\n",
      "\n",
      "a, o\n",
      "\n",
      "a, p a\n",
      "\n",
      "a, a n\n",
      "\n",
      "a, ɔ\n",
      "\n",
      "a, i\n",
      "\n",
      "a, a\n",
      "\n",
      "be, m ɛ\n",
      "\n",
      "be, m ɛ\n",
      "\n",
      "be, m i\n",
      "\n",
      "be, ð e\n",
      "\n",
      "be, s u n ɛ\n",
      "\n",
      "be, ɔ s̪ t b ɛ\n",
      "\n",
      "be, m e\n",
      "\n",
      "be, m ɛ\n",
      "\n",
      "be, ɾ m ɛ\n",
      "\n",
      "be, i\n",
      "\n",
      "be, w ɛ\n",
      "\n",
      "ce, s ɛ\n",
      "\n",
      "ce, s i\n",
      "\n",
      "ce, t e\n",
      "\n",
      "ce, t ɛ\n",
      "\n",
      "ce, s e\n",
      "\n",
      "ce, s̪ e n\n",
      "\n",
      "ce, u k ɛ\n",
      "\n",
      "ce, s ɛ\n",
      "\n",
      "ce, s e\n",
      "\n",
      "ce, a\n",
      "\n",
      "ce, s ɛ\n",
      "\n",
      "de, n ɛ\n",
      "\n",
      "de, a m e\n",
      "\n",
      "de, ð e\n",
      "\n",
      "de, a n l e\n",
      "\n",
      "de, n æ\n",
      "\n",
      "de, u n ɛ ɾ\n",
      "\n",
      "de, u b ɛ ɾ\n",
      "\n",
      "de, n e\n",
      "\n",
      "de, l ɛ\n",
      "\n",
      "de, n ɛ\n",
      "\n",
      "de, \n",
      "\n",
      "de, d̪ ɛ\n",
      "\n",
      "e, e\n",
      "\n",
      "e, e\n",
      "\n",
      "e, ɛ\n",
      "\n",
      "e, æ\n",
      "\n",
      "e, i\n",
      "\n",
      "e, ɛ\n",
      "\n",
      "e, e j e\n",
      "\n",
      "e, a\n",
      "\n",
      "e, t e\n",
      "\n",
      "e, æ\n",
      "\n",
      "e, e\n",
      "\n",
      "efe, s ɛ n f ɛ\n",
      "\n",
      "efe, m ɛ s e\n",
      "\n",
      "efe, ɛ k ɾ i\n",
      "\n",
      "efe, e n s̪ o\n",
      "\n",
      "efe, ɡ ɛ s i\n",
      "\n",
      "efe, ɛ f ɛ\n",
      "\n",
      "efe, i n ʃ o\n",
      "\n",
      "efe, ɛ s̪ e\n",
      "\n",
      "efe, \n",
      "\n",
      "efe, x i\n",
      "\n",
      "ge, ɾ ɛ\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, k æ\n",
      "\n",
      "ge, a x a s j ɛ\n",
      "\n",
      "ge, e\n",
      "\n",
      "ge, x æ\n",
      "\n",
      "ge, x ɛ\n",
      "\n",
      "ge, \n",
      "\n",
      "ge, k i\n",
      "\n",
      "hache, ɛ x a l ʃ i n\n",
      "\n",
      "hache, p a l x e\n",
      "\n",
      "hache, a\n",
      "\n",
      "hache, a x i\n",
      "\n",
      "hache, t̪ a ɾ s e\n",
      "\n",
      "hache, a ʃ t\n",
      "\n",
      "hache, f a x i\n",
      "\n",
      "hache, i k ɔ s x ɛ\n",
      "\n",
      "hache, k i\n",
      "\n",
      "hache, p a x i\n",
      "\n",
      "i, k i\n",
      "\n",
      "i, e\n",
      "\n",
      "i, \n",
      "\n",
      "i, i\n",
      "\n",
      "i, k i\n",
      "\n",
      "i, i\n",
      "\n",
      "i, i\n",
      "\n",
      "i, k u\n",
      "\n",
      "i, i\n",
      "\n",
      "i, \n",
      "\n",
      "jota, x ɔ t\n",
      "\n",
      "jota, ɔ l̪ k\n",
      "\n",
      "jota, b o s̪ a\n",
      "\n",
      "jota, x u t a\n",
      "\n",
      "jota, f ɔ t ɛ\n",
      "\n",
      "jota, ɔ t\n",
      "\n",
      "jota, o n a\n",
      "\n",
      "jota, ɔ ɾ k a\n",
      "\n",
      "jota, s̪ o\n",
      "\n",
      "jota, p ɔ s a ɾ\n",
      "\n",
      "ka, k a t\n",
      "\n",
      "ka, k a\n",
      "\n",
      "ka, k æ n\n",
      "\n",
      "ka, x a\n",
      "\n",
      "ka, ɡ a\n",
      "\n",
      "ka, k a\n",
      "\n",
      "ka, t w a\n",
      "\n",
      "ka, x o\n",
      "\n",
      "ka, i a\n",
      "\n",
      "ka, k a\n",
      "\n",
      "ele, t e l i\n",
      "\n",
      "ele, e l e s\n",
      "\n",
      "ele, ɛ l i\n",
      "\n",
      "ele, k ɛ n e\n",
      "\n",
      "ele, p s ɛ l\n",
      "\n",
      "ele, ɛ l\n",
      "\n",
      "ele, e l e\n",
      "\n",
      "ele, t ɛ m\n",
      "\n",
      "ele, t̪ a i\n",
      "\n",
      "ele, l e\n",
      "\n",
      "eme, ɛ m e n\n",
      "\n",
      "eme, ɛ j m e\n",
      "\n",
      "eme, t ɛ m l i\n",
      "\n",
      "eme, ɛ n m o\n",
      "\n",
      "eme, ɛ m e\n",
      "\n",
      "eme, e m e t\n",
      "\n",
      "eme, ð e m e\n",
      "\n",
      "eme, ɛ m ɛ\n",
      "\n",
      "eme, e m i\n",
      "\n",
      "eme, t̪ e m e\n",
      "\n",
      "ene, i\n",
      "\n",
      "ene, w ɛ n l i\n",
      "\n",
      "ene, p e n l̪ i\n",
      "\n",
      "ene, ɛ n e\n",
      "\n",
      "ene, k ɛ n ɛ s\n",
      "\n",
      "ene, e m i\n",
      "\n",
      "ene, t e n e\n",
      "\n",
      "ene, t ɛ n ɛ x\n",
      "\n",
      "ene, e i\n",
      "\n",
      "ene, ɾ ɛ m ɛ\n",
      "\n",
      "o, t ɔ\n",
      "\n",
      "o, u\n",
      "\n",
      "o, ɔ\n",
      "\n",
      "o, ɔ\n",
      "\n",
      "o, ɔ\n",
      "\n",
      "o, o\n",
      "\n",
      "o, ɛ\n",
      "\n",
      "o, ɔ\n",
      "\n",
      "o, i x\n",
      "\n",
      "o, o\n",
      "\n",
      "pe, p e\n",
      "\n",
      "pe, p i\n",
      "\n",
      "pe, p a\n",
      "\n",
      "pe, o\n",
      "\n",
      "pe, t e\n",
      "\n",
      "pe, p e s\n",
      "\n",
      "pe, p e\n",
      "\n",
      "pe, p e\n",
      "\n",
      "pe, \n",
      "\n",
      "pe, p e\n",
      "\n",
      "qu, k u\n",
      "\n",
      "qu, k u\n",
      "\n",
      "qu, k u\n",
      "\n",
      "qu, s̪ o\n",
      "\n",
      "qu, k u\n",
      "\n",
      "qu, p u a s a t i l\n",
      "\n",
      "qu, k ɔ\n",
      "\n",
      "qu, k u\n",
      "\n",
      "qu, x i\n",
      "\n",
      "qu, k u\n",
      "\n",
      "ere, k e l e\n",
      "\n",
      "ere, p ɛ ɾ i\n",
      "\n",
      "ere, e l e\n",
      "\n",
      "ere, ɛ ɾ i\n",
      "\n",
      "ere, e x ɛ\n",
      "\n",
      "ere, k ɛ ð e k u t a s o\n",
      "\n",
      "ere, e ð ɛ\n",
      "\n",
      "ere, ɛ ɾ e\n",
      "\n",
      "ere, a s æ i\n",
      "\n",
      "ere, e ɾ e s\n",
      "\n",
      "ese, ɛ s ɛ\n",
      "\n",
      "ese, e s ɛ\n",
      "\n",
      "ese, ɛ s i\n",
      "\n",
      "ese, æ s e\n",
      "\n",
      "ese, k ɛ s e n s̪\n",
      "\n",
      "ese, ɾ ɛ s̪ e\n",
      "\n",
      "ese, i s ɛ\n",
      "\n",
      "ese, ɛ s i\n",
      "\n",
      "ese, i\n",
      "\n",
      "ese, e x i\n",
      "\n",
      "te, p æ\n",
      "\n",
      "te, t e\n",
      "\n",
      "te, p e\n",
      "\n",
      "te, x a j\n",
      "\n",
      "te, t̪ i\n",
      "\n",
      "te, t u e\n",
      "\n",
      "te, e\n",
      "\n",
      "te, k ɛ\n",
      "\n",
      "te, t æ i\n",
      "\n",
      "te, i\n",
      "\n",
      "u, k ɔ ɾ\n",
      "\n",
      "u, \n",
      "\n",
      "u, ɔ\n",
      "\n",
      "u, s̪ o\n",
      "\n",
      "u, ɔ\n",
      "\n",
      "u, ɛ\n",
      "\n",
      "u, s̪ ɔ\n",
      "\n",
      "u, o\n",
      "\n",
      "u, f ɔ\n",
      "\n",
      "u, u\n",
      "\n",
      "ve, m æ n s\n",
      "\n",
      "ve, m e\n",
      "\n",
      "ve, a n e\n",
      "\n",
      "ve, u m\n",
      "\n",
      "ve, p u m ɛ\n",
      "\n",
      "ve, n ɾ n\n",
      "\n",
      "ve, m ɛ\n",
      "\n",
      "ve, m ɛ\n",
      "\n",
      "ve, o e o e\n",
      "\n",
      "File not found all_spanish_letters_recordings/aphasia_wav/aphasia/36640.wav\n",
      "equis, ɛ ɡ i s\n",
      "\n",
      "equis, e k i s\n",
      "\n",
      "equis, ɛ s k l i s\n",
      "\n",
      "equis, i t æ k æ s̪\n",
      "\n",
      "equis, b ɛ x i s t\n",
      "\n",
      "equis, ɛ l s i\n",
      "\n",
      "equis, t ɛ ɡ i\n",
      "\n",
      "equis, ɛ s i\n",
      "\n",
      "equis, ɛ k i\n",
      "\n",
      "equis, p ɛ ɾ k i\n",
      "\n",
      "ye, b u ɡ ɛ\n",
      "\n",
      "ye, k ɔ t ɛ\n",
      "\n",
      "ye, i æ n\n",
      "\n",
      "ye, j ɛ\n",
      "\n",
      "ye, ʝ j ɛ\n",
      "\n",
      "ye, j ɛ\n",
      "\n",
      "ye, ʝ ɛ\n",
      "\n",
      "ye, ɟ e\n",
      "\n",
      "ye, ð a s\n",
      "\n",
      "ye, j ɛ\n",
      "\n",
      "zeta, s ɛ ɾ a n\n",
      "\n",
      "zeta, s ɛ l s a\n",
      "\n",
      "zeta, e l s a\n",
      "\n",
      "zeta, s ɛ t a\n",
      "\n",
      "zeta, p s i ɾ ɛ ð a\n",
      "\n",
      "zeta, p ɛ p a\n",
      "\n",
      "zeta, f l ɛ t a\n",
      "\n",
      "zeta, s ɛ t a\n",
      "\n",
      "zeta, x ɛ s̪ a\n",
      "\n",
      "zeta, s ɛ l t a\n",
      "\n",
      "zeta, s ɛ l t a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"all_spanish_letters_recordings/aphasia_wav\"\n",
    "output = list()\n",
    "for record in all_recordings:\n",
    "    try:\n",
    "        record_name, transcription = record.replace(\"mp4\", \"wav\").replace(\"\\n\", \"\").split(\",\")\n",
    "        record_path = os.path.join(base_folder, record_name)\n",
    "        recognizer = model.recognize(record_path, \"spa\")\n",
    "        current_line = f\"{transcription}, {recognizer}\\n\"\n",
    "        output.append(current_line)\n",
    "        print(current_line)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\", record_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "output_folder_name = \"allosaurus_folder\"\n",
    "os.makedirs(output_folder_name, exist_ok=True)\n",
    "output_base_name = \"allosaurus_es.txt\"\n",
    "with open(os.path.join(output_folder_name, output_base_name), \"w+\") as output_file:\n",
    "    output_file.writelines(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "distinct_phones = set()\n",
    "for line in output:\n",
    "    _, ipa_transcription = line.replace(\"\\n\", \"\").split(\",\")\n",
    "    distinct_phones.update(ipa_transcription.split(\" \"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "remap = {p: p for p in distinct_phones}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "remap = {\n",
    "    '': '',\n",
    "    'ɛ': 'e',\n",
    "    'd̪': 'd̪',\n",
    "    't': 't',\n",
    "    'x': 'x',\n",
    "    'ʝ': 'j',\n",
    "    'a': 'a',\n",
    "    'u': 'u',\n",
    "    'l': 'l',\n",
    "    'b': 'b',\n",
    "    'n': 'n',\n",
    "    'o': 'o',\n",
    "    'l̪': 'l̪',\n",
    "    'm': 'm',\n",
    "    'ɔ': 'u',\n",
    "    'æ': 'e',\n",
    "    's̪': 's̪',\n",
    "    'ɾ': 'r',\n",
    "    'j': 'j',\n",
    "    'e': 'e',\n",
    "    'w': 'w',\n",
    "    'ʃ': 'ch',\n",
    "    's': 's',\n",
    "    'k': 'k',\n",
    "    'i': 'i',\n",
    "    'ɡ': 'ɡ',\n",
    "    'f': 'f',\n",
    "    't̪': 't̪',\n",
    "    'ɟ': 'y',\n",
    "    'p': 'p',\n",
    "    'ð': 'd'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aret\n",
      "xu\n",
      "e\n",
      "e\n",
      "kea\n",
      "tesarsi\n",
      "o\n",
      "pa\n",
      "an\n",
      "u\n",
      "i\n",
      "a\n",
      "me\n",
      "me\n",
      "mi\n",
      "de\n",
      "sune\n",
      "ustbe\n",
      "me\n",
      "me\n",
      "rme\n",
      "i\n",
      "we\n",
      "se\n",
      "si\n",
      "te\n",
      "te\n",
      "se\n",
      "sen\n",
      "uke\n",
      "se\n",
      "se\n",
      "a\n",
      "se\n",
      "ne\n",
      "ame\n",
      "de\n",
      "anle\n",
      "ne\n",
      "uner\n",
      "uber\n",
      "ne\n",
      "le\n",
      "ne\n",
      "\n",
      "e\n",
      "e\n",
      "e\n",
      "e\n",
      "e\n",
      "i\n",
      "e\n",
      "eje\n",
      "a\n",
      "te\n",
      "e\n",
      "e\n",
      "senfe\n",
      "mese\n",
      "ekri\n",
      "enso\n",
      "ɡesi\n",
      "efe\n",
      "incho\n",
      "ese\n",
      "\n",
      "xi\n",
      "re\n",
      "e\n",
      "e\n",
      "ke\n",
      "axasje\n",
      "e\n",
      "xe\n",
      "xe\n",
      "\n",
      "ki\n",
      "exalchin\n",
      "palxe\n",
      "a\n",
      "axi\n",
      "tarse\n",
      "acht\n",
      "faxi\n",
      "ikusxe\n",
      "ki\n",
      "paxi\n",
      "ki\n",
      "e\n",
      "\n",
      "i\n",
      "ki\n",
      "i\n",
      "i\n",
      "ku\n",
      "i\n",
      "\n",
      "xut\n",
      "ulk\n",
      "bosa\n",
      "xuta\n",
      "fute\n",
      "ut\n",
      "ona\n",
      "urka\n",
      "so\n",
      "pusar\n",
      "kat\n",
      "ka\n",
      "ken\n",
      "xa\n",
      "ɡa\n",
      "ka\n",
      "twa\n",
      "xo\n",
      "ia\n",
      "ka\n",
      "teli\n",
      "eles\n",
      "eli\n",
      "kene\n",
      "psel\n",
      "el\n",
      "ele\n",
      "tem\n",
      "tai\n",
      "le\n",
      "emen\n",
      "ejme\n",
      "temli\n",
      "enmo\n",
      "eme\n",
      "emet\n",
      "deme\n",
      "eme\n",
      "emi\n",
      "teme\n",
      "i\n",
      "wenli\n",
      "penli\n",
      "ene\n",
      "kenes\n",
      "emi\n",
      "tene\n",
      "tenex\n",
      "ei\n",
      "reme\n",
      "tu\n",
      "u\n",
      "u\n",
      "u\n",
      "u\n",
      "o\n",
      "e\n",
      "u\n",
      "ix\n",
      "o\n",
      "pe\n",
      "pi\n",
      "pa\n",
      "o\n",
      "te\n",
      "pes\n",
      "pe\n",
      "pe\n",
      "\n",
      "pe\n",
      "ku\n",
      "ku\n",
      "ku\n",
      "so\n",
      "ku\n",
      "puasatil\n",
      "ku\n",
      "ku\n",
      "xi\n",
      "ku\n",
      "kele\n",
      "peri\n",
      "ele\n",
      "eri\n",
      "exe\n",
      "kedekutaso\n",
      "ede\n",
      "ere\n",
      "asei\n",
      "eres\n",
      "ese\n",
      "ese\n",
      "esi\n",
      "ese\n",
      "kesens\n",
      "rese\n",
      "ise\n",
      "esi\n",
      "i\n",
      "exi\n",
      "pe\n",
      "te\n",
      "pe\n",
      "xaj\n",
      "ti\n",
      "tue\n",
      "e\n",
      "ke\n",
      "tei\n",
      "i\n",
      "kur\n",
      "\n",
      "u\n",
      "so\n",
      "u\n",
      "e\n",
      "su\n",
      "o\n",
      "fu\n",
      "u\n",
      "mens\n",
      "me\n",
      "ane\n",
      "um\n",
      "pume\n",
      "nrn\n",
      "me\n",
      "me\n",
      "oeoe\n",
      "eɡis\n",
      "ekis\n",
      "esklis\n",
      "itekes\n",
      "bexist\n",
      "elsi\n",
      "teɡi\n",
      "esi\n",
      "eki\n",
      "perki\n",
      "buɡe\n",
      "kute\n",
      "ien\n",
      "je\n",
      "jje\n",
      "je\n",
      "je\n",
      "ye\n",
      "das\n",
      "je\n",
      "seran\n",
      "selsa\n",
      "elsa\n",
      "seta\n",
      "psireda\n",
      "pepa\n",
      "fleta\n",
      "seta\n",
      "xesa\n",
      "selta\n",
      "selta\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5888468809073724"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    letter_translation = ''.join(remap.get(letter, '') for letter in ipa_transcription)\n",
    "    total_real_phones += len(transcription)\n",
    "    total_distance += len(transcription) + textdistance.levenshtein(transcription, letter_translation)\n",
    "    print(letter_translation)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Todos los fonemas: 0.5888468809073724"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5096153846153846"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocales = \"aeiou\"\n",
    "\n",
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    if transcription in vocales:\n",
    "        letter_translation = ''.join(remap.get(letter, '') for letter in ipa_transcription)\n",
    "        total_real_phones += len(transcription)\n",
    "        total_distance += len(transcription) + textdistance.levenshtein(transcription, letter_translation)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solo vocales: 0.5096153846153846\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a aret\n",
      "a xu\n",
      "a e\n",
      "a e\n",
      "a kea\n",
      "a tesarsi\n",
      "a o\n",
      "a pa\n",
      "a an\n",
      "a u\n",
      "a i\n",
      "a a\n",
      "i ki\n",
      "i e\n",
      "i \n",
      "i i\n",
      "i ki\n",
      "i i\n",
      "i i\n",
      "i ku\n",
      "i i\n",
      "i \n",
      "u kur\n",
      "u \n",
      "u u\n",
      "u so\n",
      "u u\n",
      "u e\n",
      "u su\n",
      "u o\n",
      "u fu\n",
      "u u\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.47058823529411764"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocales_extremas = \"aiu\"\n",
    "\n",
    "total_real_phones = 0\n",
    "total_distance = 0\n",
    "for line in output:\n",
    "    transcription, ipa_transcription = line.replace(\"\\n\", \"\").replace(\" \", \"\").split(\",\")\n",
    "    if transcription in vocales_extremas:\n",
    "        letter_translation = ''.join(remap.get(letter, '') for letter in ipa_transcription)\n",
    "        total_real_phones += len(transcription)\n",
    "        total_distance += len(transcription) + textdistance.levenshtein(transcription, letter_translation)\n",
    "        print(transcription, letter_translation)\n",
    "\n",
    "total_real_phones/total_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vocales extremas: 0.47058823529411764\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'u'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remap.get('ɔ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}