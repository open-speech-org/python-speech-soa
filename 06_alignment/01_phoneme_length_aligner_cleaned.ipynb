{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import textgrids\n",
    "from scipy.io import wavfile\n",
    "from silence_aligner import extract_segments_from_file\n",
    "import IPython.display\n",
    "from jiwer import wer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "length_std = {'sil': 0.37004250783970655,\n",
    " 'g': 0.0970459455376011,\n",
    " 'a': 0.05660433687030533,\n",
    " 'f': 0.056929615415985,\n",
    " 's': 0.10598433935792115,\n",
    " 'n': 0.044217450983390603,\n",
    " 'r': 0.025405123070675686,\n",
    " 'j': 0.06591924956009611,\n",
    " 'R': 0.0517020847447505,\n",
    " 'o': 0.060734759874077476,\n",
    " 'b': 0.06107722854276204,\n",
    " 'i': 0.04044209198174864,\n",
    " 'k': 0.09041679558761224,\n",
    " 'u': 0.050785248251638125,\n",
    " 'd': 0.053657157384060246,\n",
    " 'e': 0.04168302088249228,\n",
    " 'l': 0.05306956815151603,\n",
    " 'c': 0.08385220938537917,\n",
    " 'm': 0.05156874573425406,\n",
    " 't': 0.05078924791058343,\n",
    " 'p': 0.06496014058103297,\n",
    " 'y': 0.004456240066948667,\n",
    " 'C': 0.024831451374519697,\n",
    " 'N': 0.0,\n",
    " '': 0.646766174211673,\n",
    " 'S': 0.0}\n",
    "\n",
    "length_avg = {'sil': 0.6619947347517942,\n",
    " 'g': 0.10168757313538922,\n",
    " 'a': 0.14216359277803084,\n",
    " 'f': 0.12765944865075077,\n",
    " 's': 0.1842492552669475,\n",
    " 'n': 0.10900618568216998,\n",
    " 'r': 0.04598977151391705,\n",
    " 'j': 0.1038708272358285,\n",
    " 'R': 0.09990348885317477,\n",
    " 'o': 0.14870062878468995,\n",
    " 'b': 0.08269588485554184,\n",
    " 'i': 0.1294199589781047,\n",
    " 'k': 0.11736411443279583,\n",
    " 'u': 0.14413120538869068,\n",
    " 'd': 0.08530152426467356,\n",
    " 'e': 0.11940625321237626,\n",
    " 'l': 0.11286410173154132,\n",
    " 'c': 0.10325003239861755,\n",
    " 'm': 0.11838473491333955,\n",
    " 't': 0.07873005754645007,\n",
    " 'p': 0.06925395812614847,\n",
    " 'y': 0.11183312549768909,\n",
    " 'C': 0.12745184747265748,\n",
    " 'N': 0.05756467874794069,\n",
    " '': 0.49404709249643247,\n",
    " 'S': 0.09273662429796059}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "AUDIOS_FOLDER = \"cropped_audios\"\n",
    "TRANSCRIPTION_FOLDER = \"cropped_annotations\"\n",
    "TEXTS_FOLDER = \"texts\"\n",
    "OUTPUT_ALIGN_FOLDER = \"phoneme_length_align\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "def sent_tokenize(text):\n",
    "    return [x for x in re.split(\"\\.|,|;|:|\\n|!|¿|¡|\\?|-|—|\\(|\\)|«|»\", text) if x.replace(\" \", \"\")]\n",
    "\n",
    "\n",
    "remap = {\n",
    "    \"z\": \"s\",\n",
    "    \"v\": \"b\",\n",
    "    \"q\": \"k\",\n",
    "    \"ñ\": \"N\",\n",
    "    \"h\": \"\",\n",
    "    \"ó\": \"o\",\n",
    "    \"á\": \"a\",\n",
    "    \"é\": \"e\",\n",
    "    \"í\": \"i\",\n",
    "    \"ú\": \"u\",\n",
    "    \"x\": \"s\"\n",
    "}\n",
    "\n",
    "def calculate_token_lengths(text):\n",
    "    partial_times = list()\n",
    "    partial_std = list()\n",
    "    for letter in text:\n",
    "        letter = remap.get(letter, letter).strip().lower()\n",
    "        if letter in length_avg:\n",
    "            partial_times.append(length_avg[letter])\n",
    "            partial_std.append(length_std[letter])\n",
    "        else:\n",
    "            print(f\"Letter not found '{letter}'\")\n",
    "    return sum(partial_times), sum(partial_std)\n",
    "\n",
    "\n",
    "def safe_access(arr, i):\n",
    "    return arr[i] if i < len(arr) else \"\"\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_result(result_array, EXPECTED_TOKEN_LENGTH, SIGNAL_SEGMENT_LENGTHS, expected_signal_ratio):\n",
    "    # return (len(EXPECTED_TOKEN_LENGTH) - 1 - result_array[-1][0][-1]) + (len(SIGNAL_SEGMENT_LENGTHS) - 1 - result_array[-1][1][-1])\n",
    "    partial_results = 0\n",
    "    for calculated_segment_length_list, actual_segment_length_list in result_array:\n",
    "        partial_results += abs(\n",
    "            sum(EXPECTED_TOKEN_LENGTH[x][0]/expected_signal_ratio for x in calculated_segment_length_list) -\n",
    "            sum(SIGNAL_SEGMENT_LENGTHS[x] for x in actual_segment_length_list)\n",
    "        )\n",
    "    return partial_results\n",
    "\n",
    "def evaluate_all_results(possible_results, EXPECTED_TOKEN_LENGTH, SIGNAL_SEGMENT_LENGTHS, expected_signal_ratio):\n",
    "    return_list = list()\n",
    "    for index, result_list in enumerate(possible_results):\n",
    "        return_list.append((index, evaluate_result(result_list, EXPECTED_TOKEN_LENGTH, SIGNAL_SEGMENT_LENGTHS, expected_signal_ratio)))\n",
    "    return return_list\n",
    "\n",
    "def align_single(base_file_name):\n",
    "    frequency_from_signal, signal = wavfile.read(\n",
    "        os.path.join(\n",
    "            AUDIOS_FOLDER,\n",
    "            f\"{base_file_name}.wav\"\n",
    "        )\n",
    "    )\n",
    "    silences, frequency  = extract_segments_from_file(\n",
    "        os.path.join(\n",
    "            AUDIOS_FOLDER,\n",
    "            f\"{base_file_name}.wav\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    segments = list()\n",
    "    last_start = 0\n",
    "    for start, stop in silences:\n",
    "        segments.append((last_start, start))\n",
    "        last_start = stop\n",
    "\n",
    "    segments.append((last_start,signal.shape[-1]))\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            TEXTS_FOLDER,\n",
    "            f\"{base_file_name.replace('cropped_', '')}.txt\"\n",
    "        )\n",
    "    ) as file:\n",
    "        text = \" \".join(file.readlines())\n",
    "\n",
    "    tokens = sent_tokenize(text)\n",
    "    tokens = tokens[1:]\n",
    "    words_count = len(text.split(\" \"))\n",
    "    transcription = textgrids.TextGrid(\n",
    "        os.path.join(\n",
    "            TRANSCRIPTION_FOLDER,\n",
    "            f\"{base_file_name}.TextGrid\"\n",
    "        )\n",
    "    )\n",
    "    signal_segment_lengths = [(stop-start)/frequency for start, stop in segments]\n",
    "    expected_token_lengths = [calculate_token_lengths(text) for text in tokens]\n",
    "    EXPECTED_TOKEN_LENGTH = expected_token_lengths\n",
    "    SIGNAL_SEGMENT_LENGTHS = signal_segment_lengths\n",
    "    expected_signal_ratio = sum([x[0] for x in EXPECTED_TOKEN_LENGTH]) / sum(SIGNAL_SEGMENT_LENGTHS)\n",
    "    evaluation_stack = [(list(), 0, 0)]\n",
    "    possible_results = list()\n",
    "\n",
    "\n",
    "    def evaluate_experiment(current_result, expected_index, segment_index):\n",
    "        ciu = 0\n",
    "        local_current_max_iters = 100\n",
    "        while expected_index < len(EXPECTED_TOKEN_LENGTH) and segment_index < len(SIGNAL_SEGMENT_LENGTHS) and ciu < local_current_max_iters:\n",
    "            ciu += 1\n",
    "            expected_avg, expected_std = EXPECTED_TOKEN_LENGTH[expected_index]\n",
    "            expected_avg = expected_avg / expected_signal_ratio\n",
    "            expected_std =  0 * expected_std\n",
    "            segment_length = SIGNAL_SEGMENT_LENGTHS[segment_index]\n",
    "            if expected_avg - expected_std <= segment_length <= expected_avg + expected_std:\n",
    "                current_result.append([[expected_index], [segment_index]])\n",
    "                expected_index += 1\n",
    "                segment_index += 1\n",
    "            elif segment_length < expected_avg - expected_std:\n",
    "                cum_length = segment_length\n",
    "                cum_index = [segment_index]\n",
    "                segment_index += 1\n",
    "                while cum_length < expected_avg - expected_std and segment_index < len(SIGNAL_SEGMENT_LENGTHS):\n",
    "\n",
    "                    copy_current_result = copy.deepcopy(current_result)\n",
    "                    copy_current_result.append([[expected_index], [segment_index - 1]])\n",
    "                    evaluation_stack.append((copy_current_result, expected_index + 1, segment_index ))\n",
    "                    cum_length += SIGNAL_SEGMENT_LENGTHS[segment_index]\n",
    "                    cum_index.append(segment_index)\n",
    "                    segment_index += 1\n",
    "                current_result.append([[expected_index], cum_index])\n",
    "                expected_index += 1\n",
    "            else:\n",
    "                cum_length = expected_avg\n",
    "                cum_index = [expected_index]\n",
    "                expected_index += 1\n",
    "                while cum_length < segment_length and expected_index < len(EXPECTED_TOKEN_LENGTH):\n",
    "\n",
    "                    copy_current_result = copy.deepcopy(current_result)\n",
    "                    copy_current_result.append([[expected_index - 1], [segment_index]])\n",
    "                    evaluation_stack.append((copy_current_result, expected_index, segment_index + 1))\n",
    "                    cum_length += EXPECTED_TOKEN_LENGTH[expected_index][0]\n",
    "                    cum_index.append(expected_index)\n",
    "                    expected_index += 1\n",
    "                current_result.append([cum_index, [segment_index]])\n",
    "                segment_index += 1\n",
    "        if ciu == local_current_max_iters:\n",
    "            print(\"Stopping on max iters evaluate single\")\n",
    "        return current_result\n",
    "\n",
    "\n",
    "    MAX_ITERS = 1000\n",
    "    i = 0\n",
    "    while evaluation_stack and i<MAX_ITERS:\n",
    "        i += 1\n",
    "        # print(\"SIZE OF THE STACK\", len(evaluation_stack))\n",
    "        current_experiment = evaluation_stack.pop(0)\n",
    "        # print(current_experiment[0][-1] if len(current_experiment[0]) > 1 else current_experiment[0], current_experiment[1], current_experiment[2])\n",
    "        possible_results.append(evaluate_experiment(current_experiment[0], current_experiment[1], current_experiment[2]))\n",
    "\n",
    "    print(\"Final i\", i)\n",
    "    evaluation_results = evaluate_all_results(possible_results, EXPECTED_TOKEN_LENGTH, SIGNAL_SEGMENT_LENGTHS, expected_signal_ratio)\n",
    "    all_min_values = list(filter(lambda x: x[1] == min(evaluation_results, key=lambda x: x[1])[1], evaluation_results))\n",
    "    first_min_value = all_min_values[0]\n",
    "    first_min_value_index = first_min_value[0]\n",
    "    min_value_selected = possible_results[first_min_value_index]\n",
    "    alignment = list()\n",
    "\n",
    "    for calculated_segment_length_list, actual_segment_length_list in min_value_selected:\n",
    "        alignment.append(\n",
    "            {\n",
    "                \"text\": ' '.join([tokens[x] for x in calculated_segment_length_list]),\n",
    "                \"xmin\":  segments[actual_segment_length_list[0]][0]/frequency,\n",
    "                \"xmax\":  segments[actual_segment_length_list[-1]][1]/frequency\n",
    "\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    tg = textgrids.TextGrid()\n",
    "    tg.xmin = 0\n",
    "    tg.xmax = silences[-1][1] / frequency\n",
    "    tier = textgrids.Tier()\n",
    "    tg[base_file_name] = tier\n",
    "\n",
    "    for align in alignment:\n",
    "        tier.append(\n",
    "            textgrids.Interval(\n",
    "                align[\"text\"],\n",
    "                align[\"xmin\"],\n",
    "                align[\"xmax\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    tg.write(\n",
    "        os.path.join(\n",
    "            OUTPUT_ALIGN_FOLDER,\n",
    "            f\"{base_file_name}_generated_phoneme_length.TextGrid\"\n",
    "        )\n",
    "    )\n",
    "    transcription_from_annotated_recording = textgrids.TextGrid(\n",
    "        os.path.join(\n",
    "            TRANSCRIPTION_FOLDER,\n",
    "            f\"{base_file_name}.TextGrid\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    intervals_from_annotated_recording = transcription_from_annotated_recording[base_file_name.replace(\"cropped_\", \"\")]\n",
    "\n",
    "    wer_list = list()\n",
    "\n",
    "    current_annotation_index = 0\n",
    "    current_interval_index = 0\n",
    "    max_iters = 100\n",
    "    ci = 0\n",
    "    while current_interval_index < len(intervals_from_annotated_recording) and ci < max_iters:\n",
    "        ci += 1\n",
    "        try:\n",
    "            interval = intervals_from_annotated_recording[current_interval_index]\n",
    "            t_text = interval.text\n",
    "            t_min = interval.xmin\n",
    "            t_max = interval.xmax\n",
    "\n",
    "            a_text = alignment[current_annotation_index][\"text\"]\n",
    "            a_min = alignment[current_annotation_index][\"xmin\"]\n",
    "            a_xmax = alignment[current_annotation_index][\"xmax\"]\n",
    "\n",
    "            if a_xmax < t_max + 1:\n",
    "                wer_list.append((tokens[int(t_text)-1], a_text))\n",
    "            else:\n",
    "                interval_to_append = [t_text]\n",
    "\n",
    "                while not a_xmax < t_max + 1:\n",
    "                    current_interval_index += 1\n",
    "                    interval = intervals_from_annotated_recording[current_interval_index]\n",
    "                    t_text = interval.text\n",
    "                    t_min = interval.xmin\n",
    "                    t_max = interval.xmax\n",
    "                    interval_to_append.append(t_text)\n",
    "                value_to_append = list()\n",
    "                for i in interval_to_append:\n",
    "                    try:\n",
    "                        value_to_append.append(tokens[int(i)-1])\n",
    "                    except ValueError:\n",
    "                        print(\"Error decoding\", i)\n",
    "                wer_list.append((\"\".join(value_to_append), a_text))\n",
    "\n",
    "\n",
    "            current_interval_index += 1\n",
    "            current_annotation_index += 1\n",
    "        except IndexError:\n",
    "            print(\"Exiting on index current_interval_index\", current_interval_index, \"current_annotation_index\", current_annotation_index)\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Exiting on value error\", t_text)\n",
    "            break\n",
    "\n",
    "    wer_values = list()\n",
    "    for x in wer_list:\n",
    "        true_value = x[0].split()\n",
    "        inferred_value = x[1].split()\n",
    "        local_wer = wer(true_value, inferred_value)\n",
    "        percentaje = len(true_value)/ words_count\n",
    "        wer_values.append(local_wer * percentaje)\n",
    "    total_wer = sum(wer_values)\n",
    "    return total_wer * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "cropped_F_13_1.TextGrid\n",
      "Desired threshold, 0.05\n",
      "2807376715.761885\n",
      "Final i 497\n",
      "Exiting on value error \n",
      "================\n",
      "cropped_M_45_1.TextGrid\n",
      "Desired threshold, 0.05\n",
      "1693037607.5033379\n",
      "Letter not found 'v'\n",
      "Letter not found 'v'\n",
      "Letter not found 'v'\n",
      "Letter not found 'é'\n",
      "Letter not found 'v'\n",
      "Letter not found 'é'\n",
      "Letter not found 'q'\n",
      "Letter not found 'é'\n",
      "Letter not found 'q'\n",
      "Letter not found 'q'\n",
      "Letter not found 'q'\n",
      "Letter not found 'q'\n",
      "Letter not found 'v'\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n",
      "Stopping on max iters evaluate single\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-ee221209e39c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m# try:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mbase_file_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile_name\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\".TextGrid\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     local_wer = align_single(\n\u001B[0m\u001B[1;32m     10\u001B[0m             \u001B[0mbase_file_name\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         )\n",
      "\u001B[0;32m<ipython-input-21-92e836588279>\u001B[0m in \u001B[0;36malign_single\u001B[0;34m(base_file_name)\u001B[0m\n\u001B[1;32m    151\u001B[0m         \u001B[0mcurrent_experiment\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluation_stack\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0;31m# print(current_experiment[0][-1] if len(current_experiment[0]) > 1 else current_experiment[0], current_experiment[1], current_experiment[2])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m         \u001B[0mpossible_results\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_experiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_experiment\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_experiment\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_experiment\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    154\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Final i\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-92e836588279>\u001B[0m in \u001B[0;36mevaluate_experiment\u001B[0;34m(current_result, expected_index, segment_index)\u001B[0m\n\u001B[1;32m    131\u001B[0m                 \u001B[0;32mwhile\u001B[0m \u001B[0mcum_length\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0msegment_length\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mexpected_index\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mEXPECTED_TOKEN_LENGTH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 133\u001B[0;31m                     \u001B[0mcopy_current_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_result\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    134\u001B[0m                     \u001B[0mcopy_current_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mexpected_index\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0msegment_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m                     \u001B[0mevaluation_stack\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcopy_current_result\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexpected_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msegment_index\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[0mcopier\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_deepcopy_dispatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcopier\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36m_deepcopy_list\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    202\u001B[0m     \u001B[0mappend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 204\u001B[0;31m         \u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    205\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_deepcopy_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[0mcopier\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_deepcopy_dispatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcopier\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36m_deepcopy_list\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    202\u001B[0m     \u001B[0mappend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 204\u001B[0;31m         \u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    205\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_deepcopy_list\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[0mcopier\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_deepcopy_dispatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcopier\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 146\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/master_thesis/lib/python3.8/copy.py\u001B[0m in \u001B[0;36m_deepcopy_list\u001B[0;34m(x, memo, deepcopy)\u001B[0m\n\u001B[1;32m    201\u001B[0m     \u001B[0mmemo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    202\u001B[0m     \u001B[0mappend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 203\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    204\u001B[0m         \u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "valid_results = [\n",
    "    \"F_08_1\",\n",
    "    \"F_52_1\",\n",
    "    \"F_54_1\",\n",
    "    \"F_56_1\",\n",
    "]\n",
    "results = list()\n",
    "output_text = \"\"\n",
    "for file_name in os.listdir(TRANSCRIPTION_FOLDER):\n",
    "    print(\"================\")\n",
    "    print(file_name)\n",
    "    # try:\n",
    "    base_file_name = file_name.replace(\".TextGrid\", \"\")\n",
    "    local_wer = align_single(\n",
    "            base_file_name\n",
    "        )\n",
    "    results.append(\n",
    "        local_wer\n",
    "    )\n",
    "    output_text += f\"{base_file_name}, {local_wer}\\n\"\n",
    "\n",
    "    # except (FileNotFoundError, ValueError, IndexError) as e:\n",
    "    #     print(\"File not found on\", file_name)\n",
    "    #     output_text += f\"{base_file_name}, {e} \\n\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total_wer = sum(results)/len(results)\n",
    "output_text += f\"TOTAL_RESULTS, {total_wer}\\n\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"phnoeme_length_results.txt\", \"w+\") as results_file:\n",
    "    results_file.write(output_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}